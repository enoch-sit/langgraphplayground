# Architecture Overview - LangGraph Playground

## ğŸ¯ Design Philosophy

**Simple, Single-Port Architecture**: Everything runs through FastAPI on port **2024**

- âœ… **No separate frontend server** needed
- âœ… **No complex routing** between services
- âœ… **Easy to deploy** with docker or nginx
- âœ… **Developer-friendly** with hot reload

## ğŸ—ï¸ Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    User's Browser                        â”‚
â”‚  (JavaScript fetches from same origin - no CORS issues)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â”‚ HTTP/WebSocket
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   FastAPI Server                         â”‚
â”‚                   (Port 2024)                            â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Routes                                         â”‚    â”‚
â”‚  â”‚  â€¢ GET  /           â†’ Serve index.html         â”‚    â”‚
â”‚  â”‚  â€¢ GET  /docs       â†’ API Documentation        â”‚    â”‚
â”‚  â”‚  â€¢ GET  /health     â†’ Health check             â”‚    â”‚
â”‚  â”‚  â€¢ POST /threads    â†’ Create thread            â”‚    â”‚
â”‚  â”‚  â€¢ POST /runs/invoke â†’ Run agent               â”‚    â”‚
â”‚  â”‚  â€¢ POST /runs/stream â†’ Stream events (SSE)     â”‚    â”‚
â”‚  â”‚  â€¢ POST /runs/resume â†’ Resume after HITL       â”‚    â”‚
â”‚  â”‚  â€¢ GET  /threads/{id}/state â†’ Get state        â”‚    â”‚
â”‚  â”‚  â€¢ GET  /threads/{id}/history â†’ Checkpoints    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  LangGraph Integration                          â”‚    â”‚
â”‚  â”‚  â€¢ graph.py        â†’ Agent with NLP detection  â”‚    â”‚
â”‚  â”‚  â€¢ tools.py        â†’ Search, budget, calc      â”‚    â”‚
â”‚  â”‚  â€¢ MemorySaver     â†’ Checkpoint storage        â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â”‚ API Calls
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              External Services                           â”‚
â”‚  â€¢ AWS Bedrock (Nova Lite) â†’ LLM inference              â”‚
â”‚  â€¢ Tavily API              â†’ Web search                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ Component Breakdown

### 1. **FastAPI Application** (`src/agent/webapp.py`)

**Purpose**: Single server handling ALL requests

**Responsibilities**:
- âœ… Serve static UI (index.html)
- âœ… Handle API requests
- âœ… Manage CORS
- âœ… Provide auto-generated docs
- âœ… Stream server-sent events (SSE)

**Key Features**:
- Async/await support for non-blocking I/O
- Pydantic validation for type safety
- WebSocket-ready for real-time features
- Automatic OpenAPI schema generation

### 2. **LangGraph Agent** (`src/agent/graph.py`)

**Purpose**: Core agent with NLP-based tool detection

**Flow**:
```
User Message
    â†“
[agent node] â†’ Parse LLM output for tool calls
    â†“
    â”œâ”€â†’ Tool detected? â†’ [interrupt] â†’ Wait for approval
    â”‚                         â†“
    â”‚                    Human approves?
    â”‚                         â†“
    â””â”€â†’ [tools node] â†’ Execute tool â†’ Return to agent
                                            â†“
                                       [agent node] â†’ Final response
```

**Innovation**: NLP-based tool detection
- System prompt instructs JSON output format
- Regex + JSON parsing to detect tool intents
- Works with ANY LLM (even without native tool calling)
- 80-90% accuracy with proper prompting

### 3. **Tools** (`src/agent/tools.py`)

Three built-in tools:

1. **tavily_search_results_json**: Web search
2. **get_travel_budget**: Calculate trip costs
3. **calculator**: Math expressions

**Easy to extend**: Just add `@tool` decorated functions!

### 4. **Web UI** (`src/ui/index.html`)

**Single-page application** with vanilla JavaScript

**Features**:
- Thread management
- Chat interface
- HITL approval dialog
- State viewer
- Checkpoint navigation

**No build step**: Pure HTML/CSS/JS (can edit and refresh!)

## ğŸ”„ Request Flow Examples

### Example 1: Normal Message

```
1. User types: "Hello!"
2. Browser â†’ POST /runs/invoke
   {
     "thread_id": "abc123",
     "message": "Hello!",
     "use_hitl": true
   }
3. FastAPI â†’ LangGraph agent
4. Agent â†’ AWS Bedrock (Nova Lite)
5. LLM responds: "Hi! How can I help?"
6. No tool call detected â†’ Return directly
7. FastAPI â†’ Browser (JSON response)
8. Browser displays message
```

### Example 2: Tool Call with HITL

```
1. User types: "Search for hotels in Paris"
2. Browser â†’ POST /runs/invoke
3. FastAPI â†’ LangGraph agent
4. Agent â†’ AWS Bedrock
5. LLM responds: {"tool": "tavily_search", "args": {"query": "hotels in Paris"}}
6. NLP parser detects tool call
7. Agent â†’ [INTERRUPT] (interrupt_before=["tools"])
8. FastAPI â†’ Browser: {"status": "interrupted", "tool_calls": [...]}
9. Browser shows approval dialog
10. User clicks "Approve"
11. Browser â†’ POST /runs/resume {"approved": true}
12. Agent â†’ Execute tool â†’ Tavily API
13. Tool returns results
14. Agent â†’ AWS Bedrock (with tool results)
15. LLM generates final answer
16. FastAPI â†’ Browser (JSON response)
```

### Example 3: Streaming

```
1. User sends message
2. Browser â†’ POST /runs/stream
3. FastAPI streams Server-Sent Events (SSE):
   data: {"event": "node", "node": "agent", ...}
   data: {"event": "node", "node": "tools", ...}
   data: {"event": "interrupt", ...}
   data: {"event": "complete"}
4. Browser updates UI in real-time
```

## ğŸ”Œ Integration Points

### Port 2024 (FastAPI)

**Direct access** (development):
- <http://localhost:2024> â†’ UI
- <http://localhost:2024/docs> â†’ API docs
- <http://localhost:2024/threads> â†’ API endpoints

**Through nginx** (production):
- <http://server.com/langgraphplayground> â†’ UI
- <http://server.com/langgraphplayground/docs> â†’ API docs
- <http://server.com/langgraphplayground/threads> â†’ API endpoints

### Why Single Port?

**Advantages**:
1. **No CORS issues**: Same-origin requests
2. **Simpler deployment**: One container, one port
3. **Easier nginx config**: Single proxy target
4. **Lower latency**: No internal routing
5. **Easier debugging**: All logs in one place

**Alternative (not used)**:
- UI on port 3000 (React/Vue)
- API on port 8000 (FastAPI)
- âŒ Requires CORS configuration
- âŒ Two containers to manage
- âŒ More complex nginx routing

## ğŸš€ Deployment Options

### Option 1: Direct (Development)

```bash
uvicorn src.agent.webapp:app --port 2024
```

**Result**: Access at <http://localhost:2024>

### Option 2: LangGraph CLI (Recommended)

```bash
langgraph dev --port 2024
```

**Benefits**:
- Hot reload
- Better logging
- LangGraph-specific features

### Option 3: Docker

```bash
docker-compose up
```

**Result**: Container exposes port 2024

### Option 4: Docker + Nginx (Production)

```nginx
location /langgraphplayground/ {
    proxy_pass http://localhost:2024/;
    # ... headers ...
}
```

**Result**: Public access with SSL/auth/logging

## ğŸ” Security Considerations

### Current Setup (Development)

- âŒ No authentication
- âŒ No rate limiting
- âœ… CORS enabled for all origins
- âœ… Input validation via Pydantic

### Production Recommendations

1. **Add API Key Authentication**:
   ```python
   from fastapi import Header, HTTPException
   
   async def verify_api_key(x_api_key: str = Header(...)):
       if x_api_key != os.getenv("API_KEY"):
           raise HTTPException(403)
   ```

2. **Enable HTTPS** (nginx):
   ```nginx
   listen 443 ssl;
   ssl_certificate /path/to/cert.pem;
   ssl_certificate_key /path/to/key.pem;
   ```

3. **Rate Limiting** (nginx or middleware):
   ```nginx
   limit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;
   ```

4. **Restrict CORS**:
   ```python
   allow_origins=["https://your-domain.com"]
   ```

## ğŸ“Š Performance Characteristics

### Port 2024 (FastAPI + Uvicorn)

**Concurrency**:
- Handles 1000s of concurrent connections
- Async/await for non-blocking I/O
- Each request doesn't block others

**Memory**:
- Base: ~50MB (Python + FastAPI)
- Per thread: ~1-5KB (MemorySaver)
- Per checkpoint: ~10-50KB

**Latency**:
- Static files: <10ms
- API calls (no LLM): 10-50ms
- LLM inference: 1-5 seconds (AWS Bedrock)
- Tool execution: 500ms-2s (Tavily)

### Scaling

**Vertical** (single instance):
- CPU: 1-2 cores sufficient for 100 concurrent users
- RAM: 512MB minimum, 2GB recommended
- Disk: 1GB (includes dependencies)

**Horizontal** (multiple instances):
- Use nginx load balancing
- Shared database for MemorySaver (use SqliteSaver)
- Sticky sessions for consistency

## ğŸ› ï¸ Technology Choices Explained

### Why FastAPI over Flask?

| Feature | FastAPI | Flask |
|---------|---------|-------|
| Async support | âœ… Native | âš ï¸ Via extensions |
| Auto docs | âœ… Built-in | âŒ Manual |
| Type validation | âœ… Pydantic | âŒ Manual |
| WebSocket | âœ… Native | âš ï¸ Via Flask-SocketIO |
| Performance | âš¡ Fast | ğŸŒ Slower |
| Modern | âœ… Latest patterns | âš ï¸ Traditional |

### Why Port 2024?

- âœ… Uncommon (unlikely conflict)
- âœ… Easy to remember
- âœ… Default for LangGraph CLI
- âœ… Above 1024 (no root required)

### Why Vanilla JS over React?

| Aspect | Vanilla JS | React |
|--------|-----------|-------|
| Build step | âŒ None | âœ… Required |
| Dependencies | 0 | ~100 packages |
| Bundle size | ~5KB | ~150KB+ |
| Hot reload | âœ… Just refresh | âš ï¸ Via webpack |
| Learning curve | âœ… Simple | âš ï¸ Steeper |

**For this playground**: Simplicity wins!

## ğŸ”® Future Enhancements

### Easy Additions

1. **WebSocket for real-time**: Replace SSE with WebSocket
2. **Authentication**: Add API key middleware
3. **Multi-user**: Add user management system
4. **Persistent storage**: Switch to SqliteSaver or PostgreSQL
5. **Custom tools**: UI for creating tools without code

### Advanced Features

1. **Visual graph editor**: Drag-and-drop nodes
2. **A/B testing**: Compare different prompts
3. **Analytics dashboard**: Track usage, costs
4. **Plugin system**: Load tools dynamically
5. **Multi-model support**: Switch between LLMs

## ğŸ“ Summary

**Architecture Highlights**:
- âœ… **Single port** (2024) for everything
- âœ… **FastAPI** handles all routing
- âœ… **No frontend build** step needed
- âœ… **Easy deployment** (docker or direct)
- âœ… **Nginx-friendly** for production

**Key Innovation**:
- NLP-based tool detection works with ANY LLM
- Human-in-the-loop via interrupts
- All LangGraph concepts in one playground

**Result**: Minimal, powerful, extensible! ğŸš€
